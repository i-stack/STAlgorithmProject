# iOS 界面渲染 探究

## 目录

一、[位图](#位图)

二、[位图的产生](#位图的产生)

三、[位图如何绘制到屏幕](#位图如何绘制到屏幕)

四、[渲染流水线](#渲染流水线)

五、[屏幕撕裂及解决方案](#屏幕撕裂及解决方案)

六、[掉帧及解决方案](#掉帧及解决方案)

七、[屏幕卡顿的本质](#屏幕卡顿的本质)

八、[iOS图形渲染技术](#iOS图形渲染技术)

九、[UIView与CALayer的关系](#UIView与CALayer的关系)

十、[Core-Anmiation绘制流程](#Core-Anmiation绘制流程)

## 位图

定义：(Bitmap)屏幕上绘制图像的原始数据。

特点：

> Bitmap是一种数据结构，一个Bitmap是由 `n * m` 个像素组成，每个像素的颜色由 `RGB` 组合或者 `灰度值` 组成。
> 
> 根据位深度，Bitmap可分为1、4、8、16、24、32位图像。
> 
> 每个像素使用的Bitmap信息位数越多，可用的颜色就越多，颜色表现就越逼真，越丰富，相应的数据量越大。

## 位图的产生

位图数据是通过 CPU、GPU 协同工作得到的。

> 1、CPU是中央处理器，适合单一复杂逻辑。
> 
> 2、GPU是图形处理器，适合高并发简单逻辑。

## 位图如何绘制到屏幕

```mermaid
graph TD

电子枪["电子枪从上往下逐行扫描，扫描完成后显示器就会呈现出一帧的画面"]

回到屏幕初始位置(然后电子枪回到屏幕初始位置进行下一次扫描)

电子枪 --> 回到屏幕初始位置 --> 电子枪

```
当电子枪换行扫描时，会发出水平同步信号，水平同步信号决定CRT画一条横越屏幕线的时间；

当电子枪回到屏幕初始位置准备画下一帧画面时，会发出垂直同步信号，垂直同步信号决定从屏幕顶部画到底部，在回到初始位置的时间，代表CRT显示器的刷新率水平。

## 渲染流水线

> 1、应用处理阶段：得到图元(primitives)
> 
>> 应用对图像进行一系列的操作或者改变，将得到的图像信息传递给下一阶段，新得到的信息叫图元，通常是三角形、线段、顶点等，这个阶段在CPU阶段处理。
>
> 2、几何处理阶段：处理图元
> 
>> GPU 会对应用处理阶段得到的这部分图元进行处理，之后输出新的图元。这一阶段包括：顶点着色器、形状搭配、几何着色器。
>> 
>>> 2.1、顶点着色器(Vertex Shader)：这个阶段中会将图元中的顶点信息进行视角转换、添加光照信息、增加纹理等操作。
>>> 
>>> 2.2、形状搭配(Shape Assembly)：图元中的三角形、线段、点分别对应三个 Vertex、两个 Vertex、一个 Vertex。这个阶段会将 Vertex 连接成相对应的形状。
>>> 
>>> 2.3、几何着色器(Geometry Shader)：额外添加额外的Vertex，将原始图元转换成新图元，以构建一个不一样的模型。简单来说就是基于通过三角形、线段和点构建更复杂的几何图形。
> 
> 3、光栅化阶段：将几何处理阶段渲染之后的图元信息，转换为一系列的像素。
> 
> 4、像素处理阶段：处理像素，得到位图，这一阶段包括：片段着色器、测试与混合。
> 
>>  4.1、片段着色器：这个阶段的目的是给每一个像素 Pixel 赋予正确的颜色。颜色的来源就是之前得到的顶点、纹理、光照等信息。由于需要处理纹理、光照等复杂信息，所以这通常是整个系统的性能瓶颈。
>>  
>>  4.2、测试与混合：处理片段的前后位置以及透明度。

## 屏幕撕裂及解决方案

定义：如果在电子束开始扫描新的一帧时，位图还没有渲染好，而是在扫描到屏幕中间时才渲染完成，被放入帧缓冲器中，那么已扫描的部分就是上一帧的画面，而未扫描的部分则会显示新的一帧图像，这就造成屏幕撕裂。

单一缓存的模式下，最理想的情况就是一个流畅的流水线：每次电子束从头开始新的一帧的扫描时，CPU+GPU 对于该帧的渲染流程已经结束，渲染好的位图已经放入帧缓冲器中，这种情况下很容易发生屏幕撕裂。

### 垂直同步信号 + 双缓存机制

> 1、垂直同步信号（vertical synchronisation，Vsync）相当于给帧缓冲器加锁：当电子束完成一帧的扫描，将要从头开始扫描时，就会发出一个垂直同步信号。只有当视频控制器接收到 Vsync 之后，才会将帧缓冲器中的位图更新为下一帧，这样就能保证每次显示的都是同一帧的画面，因而避免了屏幕撕裂。
> 
> 2、双缓冲机制会增加一个新的备用缓冲器（back buffer）。渲染结果会预先保存在 `back buffer` 中，在接收到 Vsync 信号的时候，视频控制器会将 `back buffer` 中的内容置换到 `frame buffer` 中，此时就能保证置换操作几乎在一瞬间完成（实际上是交换了内存地址）。

## 掉帧及解决方案

如果在接收到 Vsync 之时 CPU 和 GPU 还没有渲染好新的位图，视频控制器就不会去替换 `frame buffer` 中的位图。这时屏幕就会重新扫描呈现出上一帧一模一样的画面。相当于两个周期显示了同样的画面，这就是所谓掉帧的情况。

### 三缓冲 Triple Buffering

在发生掉帧的时候，CPU 和 GPU 有一段时间处于闲置状态：当 A 的内容正在被扫描显示在屏幕上，而 B 的内容已经被渲染好，此时 CPU 和 GPU 就处于闲置状态。那么如果我们增加一个帧缓冲器，就可以利用这段时间进行下一步的渲染，并将渲染结果暂存于新增的帧缓冲器中。

由于增加了新的帧缓冲器，可以一定程度上地利用掉帧的空档期，合理利用 CPU 和 GPU 性能，从而减少掉帧的次数。

## 屏幕卡顿的本质

手机使用卡顿的直接原因，就是掉帧，掉帧的主要原因：

> 1、屏幕卡顿的根本原因：CPU 和 GPU 渲染流水线耗时过长，导致掉帧。
> 
> 2、Vsync 与双缓冲的意义：强制同步屏幕刷新，以掉帧为代价解决屏幕撕裂问题。
> 
> 3、三缓冲的意义：合理使用 CPU、GPU 渲染性能，减少掉帧次数。

## iOS图形渲染技术

> 1、UIKit：通过设置 `UIKit` 组件的布局以及相关属性来绘制界面。但是其并不具备在屏幕成像的能力，这个框架主要负责对用户操作事件的响应，事件经过响应链传递，核心是UIView;
> 
> 2、Core Graphics：用于运行时绘制图像，可用来绘制 `路径`、`颜色`、`阴影`、`离屏渲染`、`颜色转换` 等；
> 
> 3、Core Animation：负责组合屏幕上不同的可视内容，这些可视内容被分解为独立的图层 `CALayer` 主要负责界面的渲染；大部分工作由GPU完成；
>  
> 4、Core Image：用于运行时创建图像；
> 
> 5、OpenGL ES 和 Metal：是第三方标准，基于这些标准具体的内部实现是由对应的 GPU 厂商开发的；Metal由苹果开发；

## UIView与CALayer的关系

> 1、`UIView` 提供对 `CALayer` 功能的封装，负责界面交互；
>
> 2、`CALayer` 是 `UIView` 的属性，负责动画和渲染；
> 
>> `CALayer` 的 `content` 属性，保存设备渲染流水线渲染好的位图 `bitmap（backing store）`，也就是原始数据；
>> 
>> 当设备屏幕进行刷新时，会从 `CALayer` 中读取生成好的 `bitmap`，进而呈现到屏幕上；
>> 
>> `UIView` 好比是一个画板，`CALayer` 是画布，画板可以移动，画布负责展示；

## Core-Anmiation绘制流程

app不负责渲染，渲染是由一个独立的进程负责 `Render Server` 负责渲染。

整个渲染流程可分为：应用阶段、Render Server阶段、Display 三个阶段：

> 1、应用阶段：得到图元，通常是三角形、线段、顶点
> 
>> 视图的创建、布局计算
>> 
>> 对图层进行打包，在下一次 RunLoop 时将其发送至  Render Server；
>> 
>> app 处理用户的点击操作，在这个过程中 app 可能需要更新视图树，如果视图树发生更新，图层树也会被更新；
>> 
>> app 通过 CPU 完成对显示内容的计算；
>> 
> 2、Render Server 
> 
>> 这一阶段主要执行 metal、Core Graphics 等相关程序，并调用 GPU 在物理层上完成对图像的渲染；
>> 
>> GPU 将渲染后的位图数据存储到帧缓冲区(Frame Buffer)；
>> 
> 3、Display阶段：视频控制器将帧缓冲区的位图数据一帧一帧的显示在物理屏幕上

## 离屏渲染

无法把渲染结果直接存储到帧缓冲区，而是先暂存到其他内存区域，之后在存储到帧缓冲区，这个过程就是离屏渲染。

> 正常渲染流程：通过CPU与GPU协作，不停的将位图数据存储到帧缓冲区，视频控制器则不断地从帧缓冲区中获取内容并展示；
> 
> 离屏渲染流程：离屏渲染需要先额外创建离屏渲染缓冲区，将提前渲染好的内容放入其中，等到合适的时机再将 Offscreen Buffer 中的内容进一步叠加、渲染，完成后将结果再存储到帧缓冲区中；

### CPU离屏渲染

CPU渲染并非真正意义上的离屏渲染。如果实现了drawRect，打开Xcode调试的 `Color offscreen rendered yellow` 开关，发现这片区域不会被标记为黄色，说明Xcode并不认为这属于离屏渲染。

其实通过CPU渲染就是俗称的 `软件渲染`，而真正的离屏渲染发生在GPU。

### GPU离屏渲染
